{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.errors import OutOfBoundsDatetime\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.utils import read_jsonl, write_jsonl\n",
    "from src.visualization.visualize import paper_mpl_env, title\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4 Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt asks for shorter summaries and simpler siuations\n",
    "v2_data = pd.read_json('data/processed/ts2desc/v2.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.read_json(\"categorized_output.json\",lines=True)[[\"uuid\",\"category\"]]\n",
    "categories.rename(columns={\"category\":\"scenario_category\"}, inplace=True)\n",
    "categories[\"scenario_category\"] = categories[\"scenario_category\"].str.split(\"Category:\").str[-1].str.strip().str.removeprefix(\"'\").str.removesuffix(\"'\")\n",
    "\n",
    "top_ten = categories[\"scenario_category\"].value_counts().head(10).index.to_list()\n",
    "categories = categories[categories[\"scenario_category\"].isin(top_ten)]\n",
    "categories.to_csv(\"data/processed/scenario_categories.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorised_data = v2_data.join(categories.set_index(\"uuid\"),on=\"uuid\", how=\"inner\").drop_duplicates(subset=[\"uuid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get df with one of each category\n",
    "one_of_each = categorised_data.groupby(\"scenario_category\").first().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with paper_mpl_env():    \n",
    "    fig, axes = plt.subplots(5, 2, figsize=(16, 10))\n",
    "    axes = axes.flatten()\n",
    "    i=0\n",
    "    i_start=0\n",
    "    n_plotted = 0\n",
    "    while n_plotted < 10:\n",
    "        sample = one_of_each.iloc[i]\n",
    "        ts = sample['series']\n",
    "        desciption = sample['description']\n",
    "        desciption_tiny = title(sample['description_tiny'])\n",
    "        start = sample['metadata']['start']\n",
    "        end = sample['metadata']['end']\n",
    "        units = title(sample['metadata']['units'])\n",
    "        category = sample['scenario_category']\n",
    "\n",
    "        try:\n",
    "            x = pd.date_range(start=start, end=end, periods=len(ts))\n",
    "        except OutOfBoundsDatetime:\n",
    "            x = range(len(ts))\n",
    "            print(\"Warning: OutOfBoundsDatetime\")\n",
    "            i+=1\n",
    "            continue\n",
    "        \n",
    "\n",
    "        axes[n_plotted].plot(x,ts)\n",
    "        axes[n_plotted].set_title(desciption_tiny.strip())\n",
    "        axes[n_plotted].text(1.2, 0.90, category, fontsize=10, transform=axes[n_plotted].transAxes, fontweight='bold', ha='left')\n",
    "        # Put bold text that says \"Description: above the description\"\n",
    "        axes[n_plotted].text(1.2, 0.80, \"Description:\", fontsize=10, transform=axes[n_plotted].transAxes, fontweight='bold', ha='left')\n",
    "        # Put description in box to the right of each subplot (with text wrapping)\n",
    "        axes[n_plotted].text(1.2, 0.75, textwrap.fill(desciption.strip(), 50), fontsize=10, transform=axes[n_plotted].transAxes, va='top')\n",
    "        # Set xticks to just first and last\n",
    "        axes[n_plotted].set_xticks([x[0], x[-1]])\n",
    "        axes[n_plotted].set_ylabel(units)\n",
    "        i += 1\n",
    "        n_plotted += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"reports/2024/one_of_each.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donut Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with paper_mpl_env():\n",
    "    fig, ax = plt.subplots(figsize=(4, 2))\n",
    "    category_portions = categorised_data[\"scenario_category\"].value_counts(normalize=True)\n",
    "    plt.pie(category_portions, labels=category_portions.index, autopct='%1.1f%%', startangle=0, \n",
    "            wedgeprops={'edgecolor': 'white', 'linewidth': 1},\n",
    "            textprops={'fontsize': 8},\n",
    "            pctdistance=0.85)\n",
    "    # add a circle at the center to transform it in a donut chart\n",
    "    my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "    p=plt.gcf()\n",
    "    p.gca().add_artist(my_circle)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle\n",
    "    plt.title('Scenario Category Portion', fontsize=14, fontweight='bold')\n",
    "    plt.savefig(\"reports/2024/category_portion.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split QA Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/bdata/datasets/llms_and_timeseries/QA\n"
     ]
    }
   ],
   "source": [
    "!realpath data/processed/QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/gscratch/bdata/mikeam/TSandLanguage/notebooks/mam/ACL_2024/synthetic_datasets.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bklone-node/gscratch/bdata/mikeam/TSandLanguage/notebooks/mam/ACL_2024/synthetic_datasets.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m QA_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39m\"\u001b[39;49m\u001b[39mdata/processed/QA/all_mcq.json\u001b[39;49m\u001b[39m\"\u001b[39;49m,lines\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bklone-node/gscratch/bdata/mikeam/TSandLanguage/notebooks/mam/ACL_2024/synthetic_datasets.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m QA_df\u001b[39m.\u001b[39mjoin(categories\u001b[39m.\u001b[39mset_index(\u001b[39m\"\u001b[39m\u001b[39muuid\u001b[39m\u001b[39m\"\u001b[39m),on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muuid\u001b[39m\u001b[39m\"\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/gscratch/bdata/mikeam/anaconda3/envs/TSandLang/lib/python3.10/site-packages/pandas/io/json/_json.py:804\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n\u001b[1;32m    803\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 804\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[0;32m/gscratch/bdata/mikeam/anaconda3/envs/TSandLang/lib/python3.10/site-packages/pandas/io/json/_json.py:1012\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         data \u001b[39m=\u001b[39m ensure_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[1;32m   1011\u001b[0m         data_lines \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1012\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object_parser(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_combine_lines(data_lines))\n\u001b[1;32m   1013\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_object_parser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[0;32m/gscratch/bdata/mikeam/anaconda3/envs/TSandLang/lib/python3.10/site-packages/pandas/io/json/_json.py:1040\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1038\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1040\u001b[0m     obj \u001b[39m=\u001b[39m FrameParser(json, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mparse()\n\u001b[1;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m/gscratch/bdata/mikeam/anaconda3/envs/TSandLang/lib/python3.10/site-packages/pandas/io/json/_json.py:1173\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> 1173\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse()\n\u001b[1;32m   1175\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/gscratch/bdata/mikeam/anaconda3/envs/TSandLang/lib/python3.10/site-packages/pandas/io/json/_json.py:1366\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1362\u001b[0m orient \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morient\n\u001b[1;32m   1364\u001b[0m \u001b[39mif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1366\u001b[0m         ujson_loads(json, precise_float\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecise_float), dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1367\u001b[0m     )\n\u001b[1;32m   1368\u001b[0m \u001b[39melif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1369\u001b[0m     decoded \u001b[39m=\u001b[39m {\n\u001b[1;32m   1370\u001b[0m         \u001b[39mstr\u001b[39m(k): v\n\u001b[1;32m   1371\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m ujson_loads(json, precise_float\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecise_float)\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1372\u001b[0m     }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "QA_df = pd.read_json(\"data/processed/QA/all_mcq.json\",lines=True)\n",
    "QA_df.join(categories.set_index(\"uuid\"),on=\"uuid\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What average sealevel air pressure in hPa was used for initializing the values?\n",
      "What deviation in hPa was hypothetically assumed for the pressure readings?\n",
      "How many random storm days were included in the month?\n",
      "How many readings were collected in total over the 1month period at a rate of 1 reading every 30 minutes?\n",
      "How was the fluctuation for storm activity incorporated into the data?\n",
      "What type of data is being recorded?\n",
      "How frequently is the data sampled?\n",
      "What is the impact of the cyclone event on the data?\n",
      "What is the typical pattern of the data throughout the year?\n",
      "Are there any days with zero rainfall in the data?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(QA_df[QA_df[\"category\"] == \"description\"][\"question\"].iloc[i]) for i in range(100,110)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical MCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_mcqs = read_jsonl(\"/gscratch/bdata/datasets/llms_and_timeseries/ts2stats_mcq/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for mcq in stat_mcqs:\n",
    "    mcq[\"label\"] = mcq[\"options\"][mcq[\"answer_index\"]]\n",
    "    results.append(mcq)\n",
    "write_jsonl(results, \"data/processed/ts2stats_mcq/train.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Descriptions by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('path/to/file.jsonl', lines=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SensingResearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
