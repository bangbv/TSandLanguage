{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "For models that require training, we need to perform certain splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CATEGORIES = [\n",
    " 'Sales and Market Trends',\n",
    " 'Wildlife and Nature Observation',\n",
    " 'Environmental and Climate Data',\n",
    " 'Energy and Resource Consumption',\n",
    " 'Technological and Digital Trends',\n",
    " 'Recreational and Entertainment Trends',\n",
    " 'Transport and Traffic Trends']\n",
    "\n",
    "TEST_CATEGORIES = ['Health and Medical Data',\n",
    " 'Agricultural and Food Production',\n",
    " 'Educational and Public Services'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.read_json(\"categorized_output.json\",lines=True)[[\"uuid\",\"category\"]].drop_duplicates()\n",
    "categories.rename(columns={\"category\":\"scenario_category\"}, inplace=True)\n",
    "categories[\"scenario_category\"] = categories[\"scenario_category\"].str.split(\"Category:\").str[-1].str.strip().str.removeprefix(\"'\").str.removesuffix(\"'\")\n",
    "\n",
    "desciptions = pd.read_json(\"data/processed/ts2desc/v2.jsonl\",lines=True)\n",
    "desciptions = desciptions.join(categories.set_index(\"uuid\"),on=\"uuid\", how=\"left\")\n",
    "\n",
    "def train_test_split_categorical(df, out_path, val_size=1000, return_dfs=False, shuffle=False):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1, random_state=42)\n",
    "    df = df.join(categories.set_index(\"uuid\"),on=\"uuid\", how=\"left\")\n",
    "    train_df = df[df[\"scenario_category\"].isin(TRAIN_CATEGORIES)].sample(frac=1, random_state=42)\n",
    "    val_df = train_df.sample(n=val_size, random_state=42)\n",
    "    train_df.drop(val_df.index, inplace=True)\n",
    "    test_df = df[df[\"scenario_category\"].isin(TEST_CATEGORIES)]\n",
    "\n",
    "    if return_dfs:\n",
    "        return train_df, val_df, test_df\n",
    "    \n",
    "    train_df.to_json(os.path.join(out_path,\"train.json\"),index=False, lines=True, orient=\"records\")\n",
    "    val_df.to_json(os.path.join(out_path,\"val.json\"), index=False, lines=True, orient=\"records\")\n",
    "    test_df.to_json(os.path.join(out_path,\"test.json\"),index=False, lines=True, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_test_split_categorical(desciptions, \"data/processed/ts2stats_mcq_mike\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description MCQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['description', 'description_short', 'description_tiny', 'characteristics', 'generator', 'metadata', 'series', 'uuid', 'scenario_category', 'options']\n",
      "['description', 'description_short', 'description_tiny', 'characteristics', 'generator', 'metadata', 'series', 'uuid', 'scenario_category', 'options']\n",
      "['description', 'description_short', 'description_tiny', 'characteristics', 'generator', 'metadata', 'series', 'uuid', 'scenario_category', 'options']\n"
     ]
    }
   ],
   "source": [
    "!python src/data/make_mcq.py --input_file  data/processed/ts2desc/train.json  --output_file data/processed/ts2desc_mcq/train.json --num_total_options 4 --label_col=\"description\"\n",
    "!python src/data/make_mcq.py --input_file  data/processed/ts2desc/val.json  --output_file data/processed/ts2desc_mcq/val.json --num_total_options 4 --label_col=\"description\"\n",
    "!python src/data/make_mcq.py --input_file  data/processed/ts2desc/test.json  --output_file data/processed/ts2desc_mcq/test.json --num_total_options 4 --label_col=\"description\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical MCQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gscratch/bdata/mikeam/anaconda3/envs/TSandLang/lib/python3.10/site-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/gscratch/bdata/mikeam/anaconda3/envs/TSandLang/lib/python3.10/random.py:548: RuntimeWarning: invalid value encountered in scalar add\n",
      "  return a + (b - a) * self.random()\n"
     ]
    }
   ],
   "source": [
    "! python src/data/make_stat_mcq.py data/processed/ts2desc/train.json data/processed/ts2stats_mcq_mike/train.json\n",
    "! python src/data/make_stat_mcq.py data/processed/ts2desc/val.json data/processed/ts2stats_mcq_mike/val.json\n",
    "! python src/data/make_stat_mcq.py data/processed/ts2desc/test.json data/processed/ts2stats_mcq_mike/test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented QA\n",
    "Try splitting up the questions GPT-4 got wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/gscratch/bdata/datasets/llms_and_timeseries/Delete/v2_MCQ.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_incorrect_qa = pd.read_json(\"/gscratch/bdata/datasets/llms_and_timeseries/Delete/v2_MCQ.json\", lines=True)\n",
    "question_categories = [\"counterfactual\", \"explanation\", \"argumentation\", \"analogical\", \"fact\"]\n",
    "gpt_incorrect_qa = gpt_incorrect_qa[gpt_incorrect_qa[\"category\"].isin(question_categories)]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split_categorical(gpt_incorrect_qa, \"data/processed/qa_gpt4_incorrect\", val_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_qa = pd.read_json(\"/gscratch/bdata/datasets/llms_and_timeseries/Counterfactual/CF_Feb_1.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split_categorical(counterfactual_qa, \"data/processed/counterfactual_qa_mcq\", val_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_llava_example(row):\n",
    "    return {\n",
    "        \"id\": f'{row[\"uuid\"]}_{row[\"ts_qid\"]}',\n",
    "        \"image\": row[\"image_path\"],\n",
    "        \"conversations\": [\n",
    "          {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": f\"<image>\\n{row['description_tiny']}\\n{row['metadata']}\\n{row['question']}\"\n",
    "          },\n",
    "          {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": row[\"options\"][row[\"answer_index\"]]\n",
    "          },\n",
    "        ]\n",
    "      }\n",
    "    \n",
    "\n",
    "def make_llava_example_mcq(row):\n",
    "    options = row[\"options\"]\n",
    "    letters = [\"A\",\"B\",\"C\",\"D\"]\n",
    "    options_str = \"\\n\".join([f\"{letters[i]}) {option}\" for i, option in enumerate(options)])\n",
    "    answer_str = f\"{letters[row['answer_index']]})\"\n",
    "    return {\n",
    "        \"id\": f'{row[\"uuid\"]}',\n",
    "        \"image\": row[\"image_path\"],\n",
    "        \"conversations\": [\n",
    "          {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": f\"<image>\\nPlease answer this question by picking from the options:\\n{row['description_tiny']}\\n{row['metadata']}\\n{row['question']}\\n{options_str}\"\n",
    "          },\n",
    "          {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": answer_str\n",
    "          },\n",
    "        ]\n",
    "      }\n",
    "\n",
    "\n",
    "def make_llava_example_desc(row):\n",
    "    options = row[\"options\"]\n",
    "    np.random.shuffle(options)\n",
    "    letters = [\"A\",\"B\",\"C\",\"D\"]\n",
    "    options_str = \"\\n\".join([f\"{letters[i]}) {option}\" for i, option in enumerate(options)])\n",
    "    answer_index = options.index(row[\"description\"])\n",
    "    answer_str = f\"{letters[answer_index]}){row['description']}\"\n",
    "    return {\n",
    "        \"id\": f'{row[\"uuid\"]}',\n",
    "        \"image\": row[\"image_path\"],\n",
    "        \"conversations\": [\n",
    "          {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": f\"<image>\\nPlease pick the correct description\\n{options_str}\"\n",
    "          },\n",
    "          {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": answer_str\n",
    "          },\n",
    "        ]\n",
    "      }\n",
    "\n",
    "\n",
    "def format_examples_for_llava(df, image_dir, out_path, formatter=make_llava_example):\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        expected_image_path = os.path.join(image_dir, f\"{row['uuid']}.png\")\n",
    "        if not os.path.exists(expected_image_path):\n",
    "            continue\n",
    "        df.at[i,\"image_path\"] = f\"{row['uuid']}.png\"\n",
    "    print(len(df))\n",
    "    df = df[df[\"image_path\"]!=\"nan\"]\n",
    "    print((df[\"image_path\"]==\"nan\").sum())\n",
    "    df[\"llava_example\"] = df.apply(formatter, axis=1)\n",
    "    df[\"llava_example\"].to_json(out_path, orient=\"records\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"/gscratch/bdata/mikeam/TSandLanguage/data/processed/ts_as_img/all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qpt_incorrect_qa_train = pd.read_json(\"data/processed/qa_gpt4_incorrect/train.json\", lines=True)\n",
    "qpt_incorrect_qa_val = pd.read_json(\"data/processed/qa_gpt4_incorrect/val.json\", lines=True)\n",
    "qpt_incorrect_qa_test = pd.read_json(\"data/processed/qa_gpt4_incorrect/test.json\", lines=True)\n",
    "\n",
    "format_examples_for_llava(qpt_incorrect_qa_train, IMAGE_DIR, \"data/processed/qa_gpt4_incorrect/train_llava.json\")\n",
    "format_examples_for_llava(qpt_incorrect_qa_val, IMAGE_DIR, \"data/processed/qa_gpt4_incorrect/val_llaval.json\")\n",
    "format_examples_for_llava(qpt_incorrect_qa_test, IMAGE_DIR, \"data/processed/qa_gpt4_incorrect/test_llava.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "stats_train = pd.read_json(\"data/processed/ts2stats_mcq_mike/train.json\", lines=True)\n",
    "stats_val = pd.read_json(\"data/processed/ts2stats_mcq_mike/val.json\", lines=True)\n",
    "stats_test = pd.read_json(\"data/processed/ts2stats_mcq_mike/test.json\", lines=True)\n",
    "\n",
    "IMAGE_DIR = \"/gscratch/bdata/mikeam/TSandLanguage/data/processed/ts_as_img/all\"\n",
    "format_examples_for_llava(stats_train, IMAGE_DIR, \"data/processed/ts2stats_mcq_mike/train_llava.json\", formatter=make_llava_example_mcq)\n",
    "format_examples_for_llava(stats_val, IMAGE_DIR, \"data/processed/ts2stats_mcq_mike/val_llava.json\", formatter=make_llava_example_mcq)\n",
    "format_examples_for_llava(stats_test, IMAGE_DIR, \"data/processed/ts2stats_mcq_mike/test_llava.json\", formatter=make_llava_example_mcq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131157\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23592/1854822834.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"llava_example\"] = df.apply(formatter, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0\n",
      "19690\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23592/1854822834.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"llava_example\"] = df.apply(formatter, axis=1)\n"
     ]
    }
   ],
   "source": [
    "counterfactual_qa_train = pd.read_json(\"data/processed/counterfactual_qa_mcq/train.json\", lines=True)\n",
    "counterfactual_qa_val = pd.read_json(\"data/processed/counterfactual_qa_mcq/val.json\", lines=True)\n",
    "counterfactual_qa_test = pd.read_json(\"data/processed/counterfactual_qa_mcq/test.json\", lines=True)\n",
    "\n",
    "\n",
    "format_examples_for_llava(counterfactual_qa_train, IMAGE_DIR, \"data/processed/counterfactual_qa_mcq/train_llava.json\", formatter=make_llava_example_mcq)\n",
    "format_examples_for_llava(counterfactual_qa_val, IMAGE_DIR, \"data/processed/counterfactual_qa_mcq/val_llava.json\", formatter=make_llava_example_mcq)\n",
    "format_examples_for_llava(counterfactual_qa_test, IMAGE_DIR, \"data/processed/counterfactual_qa_mcq/test_llava.json\", formatter=make_llava_example_mcq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5779\n",
      "0\n",
      "1000\n",
      "0\n",
      "1036\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ts2desc_mcq_train = pd.read_json(\"data/processed/ts2desc_mcq/train.json\", lines=True)\n",
    "ts2desc_mcq_val = pd.read_json(\"data/processed/ts2desc_mcq/val.json\", lines=True)\n",
    "ts2desc_mcq_test = pd.read_json(\"data/processed/ts2desc_mcq/test.json\", lines=True)\n",
    "\n",
    "\n",
    "format_examples_for_llava(ts2desc_mcq_train, IMAGE_DIR, \"data/processed/ts2desc_mcq/train_llava.json\", formatter=make_llava_example_desc)\n",
    "format_examples_for_llava(ts2desc_mcq_val, IMAGE_DIR, \"data/processed/ts2desc_mcq/val_llava.json\", formatter=make_llava_example_desc)\n",
    "format_examples_for_llava(ts2desc_mcq_test, IMAGE_DIR, \"data/processed/ts2desc_mcq/test_llava.json\", formatter=make_llava_example_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5779"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5779"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ts2desc_mcq_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSandLang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
